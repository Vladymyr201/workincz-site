name: Firestore Backup
on:
  schedule:
    - cron: '0 3 * * *' # каждый день в 03:00 UTC
  workflow_dispatch: # позволяет запускать вручную

env:
  RETENTION_DAYS: 14 # хранить бэкапы 14 дней
  ERROR_LOGS_PATH: ".github/logs/firestore-backup"

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: 'Authenticate to Google Cloud'
        id: 'auth'
        uses: 'google-github-actions/auth@v1'
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'
          export_environment_variables: true
          token_format: 'access_token'
      
      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v1'
        with:
          version: '>=363.0.0'
      
      # Проверка срока действия ключей
      - name: Check service account key expiration
        run: |
          if [ -n "${GCP_SA_EMAIL}" ]; then
            echo "Проверка срока действия ключа для ${GCP_SA_EMAIL}..."
            KEY_INFO=$(gcloud iam service-accounts keys list --iam-account=${GCP_SA_EMAIL} --format="json" || echo '[]')
            
            # Простая проверка существования ключей
            if [ "$KEY_INFO" != "[]" ]; then
              echo "Ключи сервисного аккаунта найдены"
              
              # Предупреждение о необходимости проверки ключей вручную
              echo "::warning::Рекомендуется периодически проверять срок действия ключей сервисного аккаунта"
            else
              echo "Ключи для сервисного аккаунта не найдены или недостаточно прав для их просмотра"
            fi
          else
            echo "Пропуск проверки ключей: GCP_SA_EMAIL не задан"
          fi
        env:
          GCP_SA_EMAIL: ${{ secrets.GCP_SA_EMAIL }}
        continue-on-error: true
      
      - name: Check environment and permissions
        id: environment
        run: |
          # Создаем директорию для логов
          mkdir -p "${{ env.ERROR_LOGS_PATH }}"
          
          # Загружаем функции обработки ошибок
          source .github/actions/workflow-utils/error-handlers.sh || {
            echo "::error::Не удалось загрузить утилиты обработки ошибок"
            exit 1
          }
          
          # Проверяем наличие необходимых секретов
          check_required_secrets "GCP_PROJECT_ID" "GCP_SA_KEY" "GCS_BUCKET" || exit 1
          
          # Проверка доступа к проекту
          check_gcp_access "project" "${{ secrets.GCP_PROJECT_ID }}" || exit 1
          
          # Проверка доступа к бакету
          check_gcp_access "bucket" "${{ secrets.GCS_BUCKET }}" || exit 1
          
          # Проверка доступа к Firestore
          check_gcp_access "firestore" "${{ secrets.GCP_PROJECT_ID }}" || exit 1
          
          echo "✅ Проверки окружения успешно пройдены"
          
      - name: Backup Firestore with timestamp
        id: backup
        run: |
          # Загружаем функции обработки ошибок
          source .github/actions/workflow-utils/error-handlers.sh
          
          # Формируем временную метку и путь к бэкапу
          TIMESTAMP=$(date +%Y-%m-%d-%H%M%S)
          BACKUP_PATH=gs://${GCS_BUCKET}/backup-$TIMESTAMP
          
          # Сохраняем значения для использования в outputs
          echo "BACKUP_TIMESTAMP=$TIMESTAMP" >> $GITHUB_OUTPUT
          echo "BACKUP_PATH=$BACKUP_PATH" >> $GITHUB_OUTPUT
          
          # Создаем бэкап с указанием project_id
          echo "Запуск экспорта Firestore в $BACKUP_PATH для проекта ${PROJECT_ID}..."
          EXPORT_RESULT=$(gcloud firestore export $BACKUP_PATH --project=${PROJECT_ID} --collection-ids="(default)" --async 2>&1) || {
            echo "::error::Ошибка при запуске экспорта Firestore: $EXPORT_RESULT"
            exit 1
          }
          
          echo "Операция экспорта запущена. Ожидание завершения..."
          
          # Увеличиваем время ожидания и проверяем с интервалами
          MAX_ATTEMPTS=6
          ATTEMPT=0
          SUCCESS=false
          
          while [ $ATTEMPT -lt $MAX_ATTEMPTS ] && [ "$SUCCESS" = false ]; do
            ATTEMPT=$((ATTEMPT+1))
            echo "Проверка наличия файлов бэкапа (попытка $ATTEMPT из $MAX_ATTEMPTS)..."
            sleep 60
            
            if gsutil -u ${PROJECT_ID} -q stat $BACKUP_PATH/*/default_namespace/all_namespaces/kind_* 2>/dev/null; then
              echo "Бэкап создан успешно: $BACKUP_PATH"
              SUCCESS=true
              
              # Сохраняем в глобальных переменных для других шагов
              echo "backup_path=$BACKUP_PATH" >> $GITHUB_ENV
              echo "backup_timestamp=$TIMESTAMP" >> $GITHUB_ENV
              
              # Проверяем, что бэкап не пустой
              BACKUP_SIZE=$(gsutil -u ${PROJECT_ID} du -s $BACKUP_PATH | awk '{print $1}')
              if [ -z "$BACKUP_SIZE" ] || [ "$BACKUP_SIZE" -lt 1000 ]; then
                echo "::warning::Бэкап создан, но имеет подозрительно маленький размер: $BACKUP_SIZE байт"
              else
                echo "Размер бэкапа: $BACKUP_SIZE байт"
              fi
            else
              echo "Бэкап еще не завершен или файлы не найдены. Ожидание..."
            fi
          done
          
          if [ "$SUCCESS" = false ]; then
            echo "::error::Превышено максимальное время ожидания создания бэкапа. Проверьте логи Firestore."
            exit 1
          fi
        env:
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      
      # Шифрование бэкапа (опционально)
      - name: Encrypt backup
        if: env.backup_path != ''
        run: |
          if [ -n "${ENCRYPTION_KEY}" ]; then
            echo "Шифрование бэкапа..."
            
            # Получаем переменные из предыдущего шага
            BACKUP_PATH="${{ env.backup_path }}"
            BACKUP_TIMESTAMP="${{ env.backup_timestamp }}"
            
            # Простое создание контрольной суммы
            TMP_DIR="/tmp/backup-${BACKUP_TIMESTAMP}"
            TMP_ARCHIVE="${TMP_DIR}.tar.gz"
            TMP_ENCRYPTED="${TMP_DIR}.enc"
            
            echo "Подготовка архива для шифрования..."
            mkdir -p ${TMP_DIR}
            echo "Метаданные бэкапа: ${BACKUP_PATH}" > ${TMP_DIR}/backup-info.txt
            echo "Время создания: $(date)" >> ${TMP_DIR}/backup-info.txt
            echo "Путь в хранилище: ${BACKUP_PATH}" >> ${TMP_DIR}/backup-info.txt
            
            # Создаём архив с метаданными
            tar -czf ${TMP_ARCHIVE} -C /tmp backup-${BACKUP_TIMESTAMP}
            
            # Шифруем архив (используя современные параметры OpenSSL)
            echo "Шифрование архива..."
            openssl enc -aes-256-cbc -md sha512 -pbkdf2 -iter 100000 -salt \
              -in ${TMP_ARCHIVE} \
              -out ${TMP_ENCRYPTED} \
              -k "${ENCRYPTION_KEY}" \
              || { echo "Ошибка шифрования"; exit 1; }
            
            # Загружаем зашифрованный архив в хранилище
            echo "Загрузка зашифрованного архива..."
            gsutil -u ${PROJECT_ID} cp ${TMP_ENCRYPTED} ${BACKUP_PATH}.enc \
              || { echo "Ошибка загрузки зашифрованного архива"; exit 1; }
            
            # Очистка
            rm -rf ${TMP_DIR}* 
            
            echo "Бэкап зашифрован и сохранен: ${BACKUP_PATH}.enc"
          else
            echo "Шифрование пропущено (ключ не предоставлен)"
          fi
        env:
          ENCRYPTION_KEY: ${{ secrets.BACKUP_ENCRYPTION_KEY }}
          PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
        continue-on-error: true
      
      # Очистка старых бэкапов
      - name: Cleanup old backups
        run: |
          echo "Удаление бэкапов старше ${RETENTION_DAYS} дней..."
          CUTOFF_DATE=$(date -d "-${RETENTION_DAYS} days" +%Y-%m-%d)
          
          # Находим и удаляем старые бэкапы
          echo "Получение списка бэкапов из gs://${GCS_BUCKET}/backup-*"
          OLD_BACKUPS=$(gsutil -u ${PROJECT_ID} ls gs://${GCS_BUCKET}/backup-* 2>/dev/null | grep -E 'backup-[0-9]{4}-[0-9]{2}-[0-9]{2}' || echo "")
          
          if [ -z "$OLD_BACKUPS" ]; then
            echo "Старых бэкапов не найдено или бакет пуст"
          else
            echo "Найдены бэкапы, проверяем их возраст..."
            for backup in $OLD_BACKUPS; do
              BACKUP_DATE=$(echo $backup | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2}' || echo "")
              if [ -n "$BACKUP_DATE" ] && [[ "$BACKUP_DATE" < "$CUTOFF_DATE" ]]; then
                echo "Удаление $backup (старше ${RETENTION_DAYS} дней)"
                gsutil -u ${PROJECT_ID} -m rm -r $backup || echo "Ошибка при удалении $backup"
              else
                echo "Оставляем $backup (новее ${RETENTION_DAYS} дней)"
              fi
            done
          fi
          
          echo "Очистка завершена"
        env:
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          RETENTION_DAYS: ${{ env.RETENTION_DAYS }}
      
      # Сохранение диагностической информации
      - name: Save diagnostics information
        if: always()
        run: |
          # Загружаем функции обработки ошибок
          source .github/actions/workflow-utils/error-handlers.sh || true
          
          # Сохраняем информацию о выполнении
          DIAGNOSTICS_FILE="${{ env.ERROR_LOGS_PATH }}/diagnostics-$(date +%Y%m%d-%H%M%S).log"
          
          {
            echo "========== Диагностика выполнения Firestore Backup =========="
            echo "Дата/Время: $(date)"
            echo "Статус: ${{ job.status }}"
            echo "Проект: ${{ secrets.GCP_PROJECT_ID }}"
            echo "Бакет: ${{ secrets.GCS_BUCKET }}"
            echo "Путь бэкапа: ${{ env.backup_path || 'Не создан' }}"
            echo "Run ID: ${{ github.run_id }}"
            echo "Run URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            echo ""
            echo "=== Версии инструментов ==="
            echo "gcloud version:"
            gcloud version 2>&1 || echo "Ошибка получения версии gcloud"
            echo ""
            echo "=== Информация о дисковом пространстве ==="
            df -h 2>&1 || echo "Ошибка получения информации о дисковом пространстве"
          } > "$DIAGNOSTICS_FILE"
          
          echo "Диагностическая информация сохранена в $DIAGNOSTICS_FILE"
      
      # Отправка уведомления в Slack или другой сервис
      - name: Notify on completion
        if: always()
        run: |
          # Загружаем функции обработки ошибок
          source .github/actions/workflow-utils/error-handlers.sh || {
            echo "::error::Не удалось загрузить утилиты обработки ошибок"
            exit 1
          }
          
          BACKUP_PATH="${{ env.backup_path || 'Не создан' }}"
          JOB_STATUS="${{ job.status }}"
          
          PROJECT_ID="${{ secrets.GCP_PROJECT_ID }}"
          
          if [ "$JOB_STATUS" = "success" ]; then
            TITLE="Резервное копирование Firestore выполнено успешно"
            MESSAGE="Бэкап создан и сохранен в *$BACKUP_PATH*"
            DETAILS="Проект: *$PROJECT_ID*\nВремя создания: $(date +'%d.%m.%Y %H:%M:%S')"
            send_slack_notification "$WEBHOOK_URL" "success" "$TITLE" "$MESSAGE" "$DETAILS"
            echo "✅ Резервное копирование Firestore выполнено успешно!"
          else
            TITLE="Ошибка резервного копирования Firestore"
            MESSAGE="Не удалось создать бэкап для проекта *$PROJECT_ID*"
            DETAILS="Время выполнения: $(date +'%d.%m.%Y %H:%M:%S')\nПроверьте логи для получения дополнительной информации."
            send_slack_notification "$WEBHOOK_URL" "failure" "$TITLE" "$MESSAGE" "$DETAILS"
            echo "❌ Ошибка резервного копирования Firestore!"
          fi
        env:
          WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}